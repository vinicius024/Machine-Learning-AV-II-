# ğŸ“Š Projeto AVP II â€“ Machine Learning  
### Tema: **RegressÃ£o Linear â€“ PrediÃ§Ã£o de PreÃ§o de ImÃ³veis**

## ğŸ‘¥ Integrantes

- Pedro Humberto Gama de Medeiros â€“ 01741824  
- Jonas Felipe Dantas Segundo GuimarÃ£es â€“ 01720927  
- Vinicius de Freitas e Silva â€“ 01707712  

---

## â–¶ï¸ **Executar no Google Colab**

Para facilitar a correÃ§Ã£o e demonstraÃ§Ã£o, os notebooks estÃ£o disponÃ­veis online:

| Modelo | Link do Colab |
|:--------|:---------------|
| ğŸ“˜ RegressÃ£o Linear | [Abrir no Google Colab](https://colab.research.google.com/drive/1G2TSlATu9pbaPj3XmcqMKwwCM2ol4OH9?usp=sharing) |


> ğŸ’¡ *Basta clicar no link e executar as cÃ©lulas diretamente no navegador.*

---
## ğŸ¯ **Objetivo**
Desenvolver um modelo de *Machine Learning* capaz de prever o preÃ§o mÃ©dio de imÃ³veis com base em variÃ¡veis numÃ©ricas, utilizando **RegressÃ£o Linear** como modelo paramÃ©trico e **KNN Regressor** como modelo nÃ£o paramÃ©trico.  
O projeto segue as diretrizes da disciplina *Machine Learning (AVP II)*, com comparaÃ§Ã£o entre modelos, visualizaÃ§Ãµes grÃ¡ficas e relatÃ³rio tÃ©cnico.

---

## ğŸ§  **Conceitos TeÃ³ricos**

### ğŸ”¹ RegressÃ£o Linear (Modelo ParamÃ©trico)
A RegressÃ£o Linear busca ajustar uma relaÃ§Ã£o **linear** entre variÃ¡veis independentes (X) e uma variÃ¡vel dependente (Y), assumindo a forma:

\[
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_n X_n
\]

Ã‰ um modelo **paramÃ©trico**, pois depende de parÃ¢metros fixos (coeficientes Î²).  
âœ… *Vantagens:* Simples, rÃ¡pido e interpretÃ¡vel.  
âš ï¸ *LimitaÃ§Ãµes:* NÃ£o capta relaÃ§Ãµes nÃ£o lineares entre as variÃ¡veis.

---

### ğŸ”¹ KNN Regressor (Modelo NÃ£o ParamÃ©trico)
O **K-Nearest Neighbors Regressor** prevÃª o valor de uma amostra pela mÃ©dia dos **K vizinhos mais prÃ³ximos**.  
NÃ£o assume nenhuma forma de funÃ§Ã£o prÃ©-definida â€” o modelo se ajusta conforme os dados.

âœ… *Vantagens:* Capta padrÃµes complexos e nÃ£o lineares.  
âš ï¸ *LimitaÃ§Ãµes:* Mais lento com grandes bases e sensÃ­vel Ã  escala das variÃ¡veis.

---

## ğŸ  **Base de Dados**

- **Dataset:** [California Housing (Scikit-learn)](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset)
- **Registros:** 20.640 amostras  
- **VariÃ¡vel Alvo:** `MedHouseVal` (preÃ§o mÃ©dio das casas)  
- **Principais Features:**
  - `MedInc` â†’ Renda mÃ©dia da regiÃ£o  
  - `HouseAge` â†’ Idade mÃ©dia das casas  
  - `AveRooms` â†’ NÃºmero mÃ©dio de cÃ´modos  
  - `AveOccup` â†’ MÃ©dia de ocupantes  
  - `Latitude`, `Longitude`  

---

## âš™ï¸ **Metodologia**

1. **Carregamento do Dataset** via Scikit-learn  
2. **AnÃ¡lise ExploratÃ³ria (EDA)** â€“ EstatÃ­sticas, correlaÃ§Ã£o e grÃ¡ficos  
3. **PrÃ©-processamento:**
   - NormalizaÃ§Ã£o dos dados (`StandardScaler`)
   - DivisÃ£o em treino e teste (80% / 20%)
4. **Treinamento dos Modelos:**
   - RegressÃ£o Linear (`LinearRegression`)
   - KNN Regressor (`KNeighborsRegressor`)
5. **AvaliaÃ§Ã£o das MÃ©tricas:**
   - `MSE` (Erro QuadrÃ¡tico MÃ©dio)  
   - `MAE` (Erro Absoluto MÃ©dio)  
   - `RÂ²` (Coeficiente de DeterminaÃ§Ã£o)
6. **VisualizaÃ§Ãµes GrÃ¡ficas:**
   - DispersÃ£o com reta de regressÃ£o  
   - GrÃ¡fico Real vs Previsto  
   - ComparaÃ§Ã£o de RÂ² entre os modelos

---

## ğŸ“ˆ **Resultados Esperados**

| Modelo | MSE | MAE | RÂ² |
|:-------|:----|:----|:----|
| RegressÃ£o Linear | â‰ˆ 0.52 | â‰ˆ 0.48 | â‰ˆ 0.61 |
| KNN Regressor | â‰ˆ 0.45 | â‰ˆ 0.43 | â‰ˆ 0.68 |

*(Os valores podem variar ligeiramente conforme a execuÃ§Ã£o do cÃ³digo.)*

ğŸ“Š O modelo **KNN** apresentou desempenho superior em RÂ², mostrando maior capacidade de captar relaÃ§Ãµes nÃ£o lineares.  
JÃ¡ a **RegressÃ£o Linear** se destacou pela simplicidade e rapidez na execuÃ§Ã£o.

---

## ğŸ’¬ **ConclusÃµes**

- A RegressÃ£o Linear Ã© eficiente e interpretÃ¡vel, ideal para problemas com relaÃ§Ã£o aproximadamente linear.  
- O KNN, sendo nÃ£o paramÃ©trico, adapta-se melhor a relaÃ§Ãµes complexas, mas exige mais processamento.  
- A escolha do modelo ideal depende do **equilÃ­brio entre precisÃ£o, simplicidade e custo computacional.**

---

## ğŸ§© DivisÃ£o de FunÃ§Ãµes (Grupo)

| FunÃ§Ã£o                       | Integrante                                  | Responsabilidade principal                                      |
|-----------------------------|---------------------------------------------|------------------------------------------------------------------|
| LÃ­der / Programador 1       | Vinicius de Freitas e Silva â€“ 01707712      | OrganizaÃ§Ã£o geral do projeto, GitHub e cÃ³digo da RegressÃ£o Linear |
| Redator / Apresentador      | Pedro Humberto Gama de Medeiros â€“ 01741824  | RevisÃ£o teÃ³rica, escrita do relatÃ³rio e preparaÃ§Ã£o dos slides   |
| Programador 2 / Auxiliar    | Jonas Felipe Dantas Segundo GuimarÃ£es â€“ 01720927 | ImplementaÃ§Ã£o do KNN, testes e apoio na apresentaÃ§Ã£o         |

---

## ğŸ§° **Ferramentas Utilizadas**

- ğŸ **Python 3.10+**
- ğŸ““ **Google Colab**
- âš™ï¸ **Bibliotecas:**  
  `pandas`, `numpy`, `matplotlib`, `seaborn`, `scikit-learn`
- ğŸ’» **Controle de VersÃ£o:** Git + GitHub
- ğŸ“„ **RelatÃ³rio:** Overleaf (LaTeX)
- ğŸ–¼ï¸ **ApresentaÃ§Ã£o:** Google Slides / Canva

---

## ğŸš€ **Como Executar o Projeto**

1. Clone o repositÃ³rio:

   git clone https://github.com/vinicius024/Machine-Learning-AV-II-.git

2. Abra o arquivo no Google Colab:

    regressao_linear.ipynb

    knn_regressor.ipynb

3. Execute todas as cÃ©lulas.

4. Verifique as mÃ©tricas finais e gere os grÃ¡ficos.

ğŸ“š ReferÃªncias

Pedregosa et al. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, 2011.

GÃ©ron, AurÃ©lien. Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow. Oâ€™Reilly, 2023.

DocumentaÃ§Ã£o oficial: https://scikit-learn.org/stable/
